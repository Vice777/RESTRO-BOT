{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Restro_ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVHKoIkU8GvM"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv-OVjWL8Qm7"
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhEzJnW38i9b"
      },
      "source": [
        "#Import the libraries\n",
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('punkt' , quiet=True)\n",
        "\n",
        "#Extracting Source(article) from a webpage\n",
        "\n",
        "article = Article('https://ssnegi23.github.io/Group-26-AI-CHATBOT-WEBSITE/WEBSITE/index.html')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus = article.text\n",
        "\n",
        "text = corpus\n",
        "sentence_list = nltk.sent_tokenize(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PEzjCtpCQCN",
        "outputId": "e21cc665-568e-4231-f0e2-2a48bc9ee64d"
      },
      "source": [
        "nltk.download('punkt' , quiet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-j6IK8eSzr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "2a27a3fc-4079-4859-b7b6-25588c58f97a"
      },
      "source": [
        "#Extracting Source(article) from a webpage\n",
        "\n",
        "article = Article('https://www.brookings.edu/research/how-artificial-intelligence-is-transforming-the-world/')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus = article.text "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cf98b1d67285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Extracting Source(article) from a webpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.whl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'error' is an invalid keyword argument for open()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJYmarnFD-_F"
      },
      "source": [
        "text = corpus\n",
        "sentence_list = nltk.sent_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsog9Puh3XlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565293b5-26b9-415b-a4c9-5a96d61697e6"
      },
      "source": [
        "article.keywords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['python', 'chatbot', 'group']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBD2yReL9480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dacecce-d92d-498c-ae65-1454a96ad639"
      },
      "source": [
        "sentence_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HK2kAnoEQrM"
      },
      "source": [
        "#Function for greeting the user according to query\n",
        "\n",
        "def greeting_response(text):\n",
        "  text = text.lower()\n",
        "\n",
        "  bots_greetings = [\"Hello \\nHow may I assist you\" , \"Hey \\nWhat can I help you for \" , \"Hi \\nAny need for help\"]\n",
        "  user_greetings = ['hi' , 'hello' , 'greetings' , 'hey']\n",
        "\n",
        "  word = text\n",
        "  if word in text.split():\n",
        "    if word in user_greetings:\n",
        "      return random.choice(bots_greetings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY7NunjNF5GI"
      },
      "source": [
        "#sorting the sentence_list based on decreasing similarity from the given query to find the appropriate response/answer\n",
        "\n",
        "def index_sort(list_var):\n",
        "  length = len(list_var)\n",
        "  list_index = list(range(0,length))\n",
        "  x = list_var\n",
        "  for i in range(length):\n",
        "    for j in range(length):\n",
        "      if x[list_index[i]] > x[list_index[j]]:\n",
        "        temp = list_index[i]\n",
        "        list_index[i] = list_index[j]\n",
        "        list_index[j] = temp\n",
        "  \n",
        "  return list_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5PQHN8_IP-N"
      },
      "source": [
        "#Function for the best response to the query asked by the user\n",
        "\n",
        "def bots_response(user_input):\n",
        "  user_input = user_input.lower()\n",
        "  sentence_list.append(user_input)\n",
        "  bots_response = ' '\n",
        "  count_matrix = CountVectorizer()\n",
        "  cm = count_matrix.fit_transform(sentence_list)\n",
        "  similarity_score = cosine_similarity(cm[-1], cm)\n",
        "  similarity_score_list = similarity_score.flatten()\n",
        "  index = index_sort(similarity_score_list)\n",
        "  index = index[1:]\n",
        "  response_flag = 0\n",
        "  flag_count=0\n",
        "  for i in range(len(index)):\n",
        "    if similarity_score_list[index[i]] > 0.5:\n",
        "      bots_response = bots_response + '\\n' + sentence_list[index[i]]\n",
        "      response_flag = 1\n",
        "      flag_count = flag_count + 1\n",
        "    \n",
        "    if flag_count>2 :\n",
        "      break\n",
        "  \n",
        "  if response_flag == 0:\n",
        "    bots_response = bots_response + 'I apologoze , Item Not Found'\n",
        "  \n",
        "  sentence_list.remove(user_input)\n",
        "\n",
        "  return bots_response\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu9pyuNuTN5K"
      },
      "source": [
        "#Main Function\n",
        "print(\"\\nRESTRO Bot : Hello! I am RESTRO Bot , private chat bot appliacation\")\n",
        "print(\"I will be refering to an article - 'How artificial intelligence is transforming the world'\")\n",
        "print(\"\\nRESTRO Bot : Give a query for me to answer : \\n\")\n",
        "\n",
        "break_list = ['exit' , 'bye' , 'break' , 'quit' , 'cya' , 'thank you for your time']\n",
        "\n",
        "while(True):\n",
        "  user_input = str(input())\n",
        "  if user_input.lower() in break_list:\n",
        "    print('RESTRO Bot : Thanks you your cooperation. You may have a good day')\n",
        "    break\n",
        "  else:\n",
        "    if greeting_response(user_input) != None:\n",
        "      print('RESTRO Bot :' + greeting_response(user_input))\n",
        "    else:\n",
        "      print('RESTRO Bot :' + bots_response(user_input ))\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}